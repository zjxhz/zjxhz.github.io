---
layout: post
title: 机器学习之「壹零壹」
description: 
category: articles
tags: 
---
### 回顾
上一篇我们提到了如何用「梯度下降法」来找到「使得代价函数J最小的参数a」。我不得不用了几个公式，还用到了一点微积分的知识。但如果你对微积分不太了解，也并没有什么关系，只需要从几个图形化的表示中获得一点直观上的印象，并记住结论中的几个公式即可。

### 为什么不用「解方程法」？
如果对比「梯度下降法」和「解方程法」，你可能会发现，前者要简单有效得多。为什么还需要后者呢？随着学习的深入，你会慢慢了解到，随着情形变得复杂，前者的算法的「时间复杂度」其实比后者要高。虽然在这个简单的例子中没有办法体现。所以在数据量和模型本身并不复杂的情况下，也许是前者更为合适。

### 更进一步
不管使用哪种方法，我们至少得到了一致性的结果。那就是J的最优值是37.16（a此时取值4.786）。那么，能不能更好呢？

前面我们一直在假设，房价y和面积X的关系是：

`y = aX`

熟悉代数的同学会发现，这只是「线性」关系的一个特例。更一般的，我们会假设：

`y = aX + b`

所以，我们之前的讨论，都是在假设b为0。因为这是一种符合常识的做法：即假设X面积为0的时候，价格也为0。话是这么说没错，但这种简单的模型不一定是最适合预测房价的。换句话说，也许这个简单的「特例模型」可以很好地解释当X为0的时候的情况，但不一定对于其他的X有更好的预测。到底结果怎么样呢？让我们来试试。

前面我们计算J的方式是通过代入已知的面积和房价的值，从而得到一个一元二次方程：

$$ J = { 11000 * (a^2) - 105300 * a + 252225) \over 6 } $$

现在，因为多了一个参数b，J的值现在取决了两个参数a和b了。如果还是像以前那样代入已知数值，我们仍然可以得到一个二元二次方程，但是这个表达式的项会比较多。所以，这次，我们来换一种方式。另外，为了和机器学习领域的说法更为统一，我们现在用h来代表我对房价的「预测」（或称假设hypothesis），而用y表示实际上的房价的值。也就是说，我们「预测」房价h和面积X的关系是：

`h = aX + b`

这里，虽然只是简单地把y换成了h，但是这后面的想法很有意思。因为这变成了一种「假设」，而非事实。而假设和事实之间是有可能存在偏差的。我们的任务，就是找到最优的参数a和b，使得我们的代价函数J最小。而且这里还有个很有意思的地方（有意思才见鬼了！），是我们是在对参数a和b求值，而不是对X求值，因为X所代表的面积是给定的已知值。而且，对于不同的X，我们的h其实变成了多个方程(对于我们的例子，也就是如下几个)。了解这一点非常重要。

`h1 = 50a + b`

`h2 = 60a + b`

`h3 = 70a + b`

我们的代价函数J又如何表示呢？如果用h来表示，则为

`J = ((h1 - y1) ^ 2  + (h2 - y2) ^ 2 + (h3 - y3) ^ 2)/ (3 * 2)`

还是和以前一样，如果我们代入所有的已知值X和y。那么J变成了一个关于a和b的二元二次方程。如果用「解方程法」来求解，那么还是求当J为0时，a和b的取值。但是，这里我们打算用「梯度下降法」。

通过前一篇我们知道，如果J是对于a的一元二次方程，那么计算a的值的关键在于对a进行「求导」，然后用一定的学习率alpha来逐步「优化」J的值以至收敛。类似地，对于一个二元方程，我们要求的，则是计算a和b对于J的「偏微分」。同样的，下面的推导过程仍然会涉及到微积分的知识；特别的，会要求你知道偏微分是怎么回事，以及微积分求导的几个「法则」（也就是公式）。如果你觉得头大，直接看图和结论部分即可。但是明白推导过程并亲自推导会加深你对这个算法的认识。

我们当然可以根据二元二次方程来计算a和b的偏微分，但是因为那样多项式展开看起来比较复杂。所以我们打算使用「链式法则」：

`dJ / da = dJ / dh * dh / da`

也就是说，为了计算J对于a和b的偏微分，我们首先计算J对于h的微分，然后再计算h对于a和b的偏微分。具体地来讲，
根据幂函数的求导公式，我们去掉平方，得到J对于h的导数，为：

`dJ / dh = ((h1 - y1) + (h2 - y2) + (h3 - y3)) / 3`

而h对于a的导数则为：

`dh /da = X`

比如：
`dh1 / da = 50`

而h对于b的导数则为常数1。所以：

`dJ / da = ((h1 - y1) * X1 + (h2 - y2) * X2 + (h3 - y3) * X3) / 3`

`dJ / db = ((h1 - y1) * 1 + (h2 - y2) * 1 + (h3 - y3) * 1) / 3`

然后就是像之前一样，循环更新a和b的值：

`a := a - alpha * dJ / da`

`b := b - alpha * dJ / db`

如果alpha取值为xxx，那么我们可以得到：

`a = x; b = xx;`

此时J的值为xxx，比37.16又好了不少，太好了！可是……我猜已经没有人能看懂我在说什么了，即使你有耐心看到现在——除非你本来就懂。