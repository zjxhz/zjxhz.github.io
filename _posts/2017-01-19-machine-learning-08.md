---
layout: post
title: 机器学习之「壹零零零」
description: 从真实的数据来看下过度拟合（Overfitting）问题
category: articles
tags: 
---

前面我们说到，通过增加单个特征（例如面积）的高幂次到我的预测中，可以有效地减小偏差。然而，这么做不总是奏效的，而且会导致一种叫做「过度拟合」的问题。下面我们来看一个具体的问题。

为了得到有效的数据，我先是去深圳市房地产管理中心的网站查询了一下历史成交数据。不幸的是，单个房产的成交数据好像并不对外开放（地产界的朋友如果知道请告知），而是只有一个概要，比如某个区在某个月的成交价格。于是我只好用Scrapy写了一个爬虫去某地产中介的网站爬到了大约一万四千多条数据。

下面以本人居住的福田的皇岗片区为例，来验证一下我们的机器学习算法。该地产中介在这个地区挂出了200多套房子，我们抽取其中前面的100套房子作为「训练样本」，然后再测试接下来的三套房子，看看实际的偏差和「过度拟合」的问题。

首先，让我们假设房价和面积的关系还是简单的线性关系，即：

$$ h(X) = \theta_0 + \theta_1 X $$

这个时候，通过运用之前介绍的算法，我们可以得知$$\theta_0$$和$$\theta_1$$的值分别为-2.803和5.643，偏差约为1838。

![](/images/ml_hgLiner.png)

从图中看，这个简单的算法不算好，但也还算合理。如果我们测试接下来的几条「新」数据（也就是不在训练样本中的数据），会发现大致如下的偏差：

| 序号 | 面积 | 实际价格 | 预测价格 | 差价 | 偏差率
| --- | ---- | ----    | ------ | ---   | ----
| 1   | 432 | 1950 | 2435 | 485 | 24.9%
| 2   | 66 | 380 | 370 | 10 | 2.7%
| 3   | 68 | 382 | 381 | 1 | 0.3%

如果…我们增加面积的幂次并作为额外的特征加入我的预测模型呢？也就是：

$$ h(X) = \theta_0 + \theta_1 X + \theta_2 X^2 + \theta_3 X^3 ... $$ 

我们设置最大次幂为8，也就是：

$$ h(X) = \theta_0 + \theta_1 X + \theta_2 X^2 + ... + \theta_8 X^8 $$ 

这么一来，我们的偏差会从1838降低到约1640。可以看到，提升并不十分明显。而且，我们得到了一张奇怪的图：

![](/images/ml_hg8.png)

这张图之所以奇怪，是因为虽然它让更多的点落到了预测的曲线附近，但是这个图看起来明显不合理。你可以看到，在面积接近200平的时候，价格陡然下跌了。这是毫无道理的。如果用这个算法来预测刚才那三条数据，会发现对测试数据1的预测有非常大的偏差，甚至出现了负数。

| 序号 | 面积 | 实际价格 | 预测价格 | 差价 | 偏差率
| --- | ---- | ----    | ------ | ---   | ----
| 1   | 432 | 1950 | **-269113439** | 269115389 | -13800789.2%
| 2   | 66 | 380 | 377 | 3 | 0.8%
| 3   | 68 | 382 | 389 | 7 | 1.8%

这个时候我们需要在代价函数中规范（regularize）参数。简单地讲，就是对于各个参数施加一定的「惩罚」，使得其对结果的影响不至于过大，从而得到一条相对平滑，也更合理的曲线。
